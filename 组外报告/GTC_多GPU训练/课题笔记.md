# 多GPU训练课程笔记


# 异步SGD

# Batch Size对训练过程的影响

# LARS

## Horovod

1. Horovod 初始化
`
import horovod as hvd
hvd.init()
`

2. 指定GPU
`
config = tf.ConfgProto()
config.intra_op_parallelism_threads = 1
config.gpu_options.visible_device_list = str(hvd.local_rank())
`

3. 分布式优化器
`
opt = hvd.DistributedOptimizer(opt)
`
同步初始化
`
def sync(self, sess):
  sync_op = hvd.broadcast_global_variables(0)
  sess.run(sync_op)
`
